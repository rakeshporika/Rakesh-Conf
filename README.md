
# ğŸ§© Project README â€” ArchViz: LLM based Architectural Evolution Analyzer

## ğŸ“˜ Overview

**ArchViz** analyzes the **architectural evolution** of Python repositories using static-analysis metrics and LLM-driven insights.
It extracts release history, builds dependency graphs, tracks structural drift, visualizes results, and now generates AI-based summaries.

âœ… **Completion Stages:** Stages 1 â€“ 6

* **Stage 1 â€“ Scope & Success Criteria**â€‚(*Project_Scope.docx*)
* **Stage 2 â€“ Version History Extraction**â€‚(tags / commits / changed files)
* **Stage 3 â€“ Dependency Graphs & Metrics**â€‚(imports, fan-in/out, complexity)
* **Stage 4 â€“ Evolution Differencing**â€‚(added / removed modules & edges)
* **Stage 5 â€“ Visualization MVP**â€‚(interactive Streamlit dashboard)
* **Stage 6 â€“ LLM Insights & Summaries**â€‚(LLM-based analysis & PDF reports)

---

## âš™ï¸ Environment Setup

```bash
# 1. Clone (skip if already local)
git clone <your-project-repo-url>
cd <your-project-folder>

# 2. Create and activate a virtual environment
python -m venv environment
source environment/bin/activate      # Windows: environment\Scripts\activate

# 3. Install dependencies
pip install -U pip
pip install pandas pydriller GitPython tqdm pyarrow networkx radon streamlit plotly pyvis openai python-dotenv reportlab
```

---

## ğŸ”‘ Before Running â€” Set Up Your OpenAI API Key

1. Create an API key at **[https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)**
2. Add it as an variable in the app.py python file (recommended)

   * **Stage5_app/app.py**

     ```powershell
     OPENAI_API_KEY "sk-yourkeyhere"
     ```

3. âš ï¸ **Usage note:** Each run uses API credits. Ensure your OpenAI account has funds or a subscription before using the Insights tab.

---

## ğŸ“‚ Folder Structure

```
project-root/
â”œâ”€â”€ external/fastapi/                # Target repo clone
â”œâ”€â”€ data/fastapi/
â”‚   â”œâ”€â”€ curated/                     # CSV & Parquet outputs + insights
â”‚   â”œâ”€â”€ logs/                        # JSON run logs
â”‚   â””â”€â”€ raw/                         # Stage 2 metadata
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ stage2_extract.py
â”‚   â”œâ”€â”€ stage3_build_graphs.py
â”‚   â”œâ”€â”€ stage4_diff.py
â”‚   â””â”€â”€ load_dataset.py
â”œâ”€â”€ stage5_app/
â”‚   â”œâ”€â”€ app.py                       # Streamlit dashboard
â”‚   â”œâ”€â”€ load_data.py                 # Cached loaders
â”‚   â”œâ”€â”€ viz_utils.py                 # Graph helpers
â””â”€â”€ README.md
```

---

## ğŸ—ï¸ Stage 2 â€” Version History Extraction

Extract tags, commits, and changed files using **PyDriller** â†’ CSVs.

```bash
git clone https://github.com/fastapi/fastapi.git external/fastapi
python scripts/stage2_extract.py
```

**Outputs**

```
data/fastapi/curated/{versions,commits,files_changed}.csv
data/fastapi/raw/run_metadata.json
```

---

## ğŸ§  Stage 3 â€” Dependency Graphs & Metrics

Parses imports per tag, builds module graphs, and computes metrics.

```bash
python scripts/stage3_build_graphs.py
```

**Outputs**

```
data/fastapi/curated/{modules,edges,metrics}.csv
data/fastapi/logs/stage3_run.json
```

---

## ğŸ” Stage 4 â€” Evolution Differencing

Compares successive versions â†’ detects added/removed modules & edges, metric deltas, and drift.

```bash
python scripts/stage4_diff.py
```

**Outputs**

```
data/fastapi/curated/
  â”œâ”€â”€ changes_modules.csv
  â”œâ”€â”€ changes_edges.csv
  â”œâ”€â”€ changes_metrics.csv
  â””â”€â”€ drift_summary.csv
```

---

## ğŸ’¡ Stage 5 â€” Interactive Visualization (App)

Explore architecture and evolution via a **Streamlit dashboard**.

```bash
cd stage5_app
streamlit run app.py
```

**Features**

* Tag selector + diff view
* Interactive PyVis dependency graph
* Metrics tables & histograms
* Drift summary and metric deltas
* Auto-selected â€œmost changedâ€ release pair

---

## ğŸ¤– Stage 6 â€” AI Insights & Summaries

**Purpose:** Leverage LLMs to create human-readable analytical reports.

**Access:** Tab 4 (Insights) inside the Streamlit app.

**Provides**

1. **Non-technical overview** (plain-language summary, 6â€“7 lines)
2. **Technical architecture summary** (metrics and structure insight, 6â€“7 lines)
3. **Evolution insights** (per-pair LLM bullets + charts)
4. **Comparative context & maintainability** (benchmark vs common frameworks)
5. **Visualizations:** growth over time, fan-in hotspots, complexity trends, and release churn
6. **ğŸ“„ Export as PDF** button to save AI report for presentations or papers

**Runs with:** OpenAI GPT-4o-mini (default) or any model set via `OPENAI_MODEL`.

---

## âœ… Validation Checklist

| Check               | Expected Result                           |
| ------------------- | ----------------------------------------- |
| `versions.csv`      | 1 row per tag                             |
| `edges.csv`         | Internal imports only                     |
| `metrics.csv`       | Non-negative metrics                      |
| `drift_summary.csv` | Valid per-pair counts                     |
| Streamlit App       | All tabs load without error               |
| Insights Tab        | Shows LLM summaries + charts + PDF export |

---

## ğŸš€ Future Extensions

* Auto-generate `insights.csv` for auditing LLM outputs.
* Optional Docker packaging (Stage 7, future).
* Support for local LLMs (Ollama / LM Studio) to reduce API costs.

---

> **Tip ğŸ’¡** The Insights tab uses your OpenAI credits per request (typically a few cents each).
> Re-runs are cached to avoid repeat charges.
