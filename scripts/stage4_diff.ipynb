{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb81d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Stage 4 — Evolution Differencing between successive tags.\n",
    "\n",
    "Inputs (from Stage 3):\n",
    "  data/<repo_slug>/curated/versions.csv\n",
    "  data/<repo_slug>/curated/modules.csv\n",
    "  data/<repo_slug>/curated/edges.csv\n",
    "  data/<repo_slug>/curated/metrics.csv\n",
    "\n",
    "Outputs (curated):\n",
    "  changes_modules.csv  (version_from,version_to,tag_from,tag_to, change_type, module)\n",
    "  changes_edges.csv    (version_from,version_to,tag_from,tag_to, change_type, src_module, dst_module)\n",
    "  changes_metrics.csv  (version_from,version_to,tag_from,tag_to, module, fan_in_delta, fan_out_delta, cyclomatic_delta, centrality_delta)\n",
    "  drift_summary.csv    (per tag pair rollups: counts + cycles + spike indicators)\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Set, Dict, List\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------- CONFIG -------------------\n",
    "REPO_SLUG = \"fastapi\"\n",
    "CURATED_DIR = Path(f\"../data/{REPO_SLUG}/curated\")\n",
    "\n",
    "# Spike thresholds (tune as needed)\n",
    "FAN_IN_SPIKE_ABS = 10         # absolute increase\n",
    "FAN_IN_SPIKE_REL = 0.5        # +50% relative\n",
    "CYCLO_SPIKE_ABS = 10          # absolute cyclomatic increase\n",
    "CYCLO_SPIKE_REL = 0.5         # +50% relative\n",
    "MAX_CYCLE_ENUM = 1000         # cap on cycles enumeration to keep runtime sane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a659e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- IO -------------------\n",
    "def load_df(name: str) -> pd.DataFrame:\n",
    "    p_parquet = CURATED_DIR / f\"{name}.parquet\"\n",
    "    p_csv = CURATED_DIR / f\"{name}.csv\"\n",
    "    if p_parquet.exists():\n",
    "        return pd.read_parquet(p_parquet)\n",
    "    return pd.read_csv(p_csv)\n",
    "\n",
    "def save_csv(df: pd.DataFrame, name: str):\n",
    "    out = CURATED_DIR / name\n",
    "    df.to_csv(out, index=False)\n",
    "    return out\n",
    "\n",
    "# ------------------- UTILS -------------------\n",
    "def build_graph(edges_df: pd.DataFrame) -> nx.DiGraph:\n",
    "    G = nx.DiGraph()\n",
    "    if not edges_df.empty:\n",
    "        G.add_edges_from(edges_df[[\"src_module\",\"dst_module\"]].itertuples(index=False, name=None))\n",
    "    return G\n",
    "\n",
    "def count_cycles_delta(G1: nx.DiGraph, G2: nx.DiGraph) -> Tuple[int,int]:\n",
    "    \"\"\"\n",
    "    Approx cycles via strongly-connected components (SCC) of size>1.\n",
    "    Returns (#cycles_like in G2 not in G1, #cycles_like removed from G1).\n",
    "    We approximate cycle presence by the set of nodes in SCCs>1.\n",
    "    \"\"\"\n",
    "    def scc_nodes(G):\n",
    "        return frozenset(frozenset(c) for c in nx.strongly_connected_components(G) if len(c) > 1)\n",
    "    s1, s2 = scc_nodes(G1), scc_nodes(G2)\n",
    "    new = len([c for c in s2 if c not in s1])\n",
    "    removed = len([c for c in s1 if c not in s2])\n",
    "    return new, removed\n",
    "\n",
    "def metrics_spike_flags(prev: pd.Series, curr: pd.Series) -> Dict[str, bool]:\n",
    "    flags = {}\n",
    "    # fan_in spike\n",
    "    fi0, fi1 = prev.get(\"fan_in\", 0), curr.get(\"fan_in\", 0)\n",
    "    flags[\"fan_in_spike\"] = (fi1 - fi0 >= FAN_IN_SPIKE_ABS) or (fi0 > 0 and (fi1 - fi0)/fi0 >= FAN_IN_SPIKE_REL)\n",
    "    # cyclomatic spike\n",
    "    c0, c1 = prev.get(\"cyclomatic\", 0), curr.get(\"cyclomatic\", 0)\n",
    "    flags[\"cyclomatic_spike\"] = (c1 - c0 >= CYCLO_SPIKE_ABS) or (c0 > 0 and (c1 - c0)/c0 >= CYCLO_SPIKE_REL)\n",
    "    return flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de4535d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- MAIN -------------------\n",
    "versions = load_df(\"versions\").sort_values(\"date\").reset_index(drop=True)\n",
    "modules  = load_df(\"modules\")\n",
    "edges    = load_df(\"edges\")\n",
    "metrics  = load_df(\"metrics\")\n",
    "\n",
    "# Prepare outputs\n",
    "changes_modules_rows = []\n",
    "changes_edges_rows   = []\n",
    "changes_metrics_rows = []\n",
    "drift_summary_rows   = []\n",
    "\n",
    "# Pair successive tags\n",
    "pairs = list(zip(versions.iloc[:-1].itertuples(index=False), versions.iloc[1:].itertuples(index=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2886d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stage 4 — tag pairs: 100%|██████████| 24/24 [00:01<00:00, 12.26it/s]\n"
     ]
    }
   ],
   "source": [
    "for prev_row, curr_row in tqdm(pairs, desc=\"Stage 4 — tag pairs\"):\n",
    "    v0, v1 = int(getattr(prev_row, \"id\")), int(getattr(curr_row, \"id\"))\n",
    "    t0, t1 = str(getattr(prev_row, \"tag\")), str(getattr(curr_row, \"tag\"))\n",
    "    \n",
    "    # Slice per tag\n",
    "    m0 = modules[modules[\"tag\"] == t0].copy()\n",
    "    m1 = modules[modules[\"tag\"] == t1].copy()\n",
    "    e0 = edges[edges[\"tag\"] == t0].copy()\n",
    "    e1 = edges[edges[\"tag\"] == t1].copy()\n",
    "    x0 = metrics[metrics[\"tag\"] == t0].set_index(\"module\")\n",
    "    x1 = metrics[metrics[\"tag\"] == t1].set_index(\"module\")\n",
    "    \n",
    "    # 1) Modules added/removed\n",
    "    set_m0 = set(m0[\"module\"])\n",
    "    set_m1 = set(m1[\"module\"])\n",
    "    added_modules   = sorted(set_m1 - set_m0)\n",
    "    removed_modules = sorted(set_m0 - set_m1)\n",
    "\n",
    "    for mod in added_modules:\n",
    "        changes_modules_rows.append({\"version_from\": v0, \"version_to\": v1, \"tag_from\": t0, \"tag_to\": t1,\n",
    "                                        \"change_type\": \"module_added\", \"module\": mod})\n",
    "    for mod in removed_modules:\n",
    "        changes_modules_rows.append({\"version_from\": v0, \"version_to\": v1, \"tag_from\": t0, \"tag_to\": t1,\n",
    "                                        \"change_type\": \"module_removed\", \"module\": mod})\n",
    "\n",
    "    # 2) Edges added/removed\n",
    "    set_e0 = set(map(tuple, e0[[\"src_module\",\"dst_module\"]].itertuples(index=False, name=None)))\n",
    "    set_e1 = set(map(tuple, e1[[\"src_module\",\"dst_module\"]].itertuples(index=False, name=None)))\n",
    "    added_edges   = sorted(set_e1 - set_e0)\n",
    "    removed_edges = sorted(set_e0 - set_e1)\n",
    "\n",
    "    for s, d in added_edges:\n",
    "        changes_edges_rows.append({\"version_from\": v0, \"version_to\": v1, \"tag_from\": t0, \"tag_to\": t1,\n",
    "                                    \"change_type\": \"edge_added\", \"src_module\": s, \"dst_module\": d})\n",
    "    for s, d in removed_edges:\n",
    "        changes_edges_rows.append({\"version_from\": v0, \"version_to\": v1, \"tag_from\": t0, \"tag_to\": t1,\n",
    "                                    \"change_type\": \"edge_removed\", \"src_module\": s, \"dst_module\": d})\n",
    "\n",
    "    # 3) Metrics deltas (only modules in both)\n",
    "    common = sorted(set_m0 & set_m1)\n",
    "    for mod in common:\n",
    "        prev_metrics = x0.loc[mod] if mod in x0.index else pd.Series()\n",
    "        curr_metrics = x1.loc[mod] if mod in x1.index else pd.Series()\n",
    "        row = {\n",
    "            \"version_from\": v0, \"version_to\": v1, \"tag_from\": t0, \"tag_to\": t1, \"module\": mod,\n",
    "            \"fan_in_delta\":     int(curr_metrics.get(\"fan_in\", 0)) - int(prev_metrics.get(\"fan_in\", 0)),\n",
    "            \"fan_out_delta\":    int(curr_metrics.get(\"fan_out\", 0)) - int(prev_metrics.get(\"fan_out\", 0)),\n",
    "            \"cyclomatic_delta\": int(curr_metrics.get(\"cyclomatic\", 0)) - int(prev_metrics.get(\"cyclomatic\", 0)),\n",
    "            \"centrality_delta\": float(curr_metrics.get(\"centrality_degree\", 0.0)) - float(prev_metrics.get(\"centrality_degree\", 0.0)),\n",
    "        }\n",
    "        changes_metrics_rows.append(row)\n",
    "\n",
    "    # 4) Cycle/Drift summary (approx)\n",
    "    G0 = build_graph(e0)\n",
    "    G1 = build_graph(e1)\n",
    "    new_cycles, removed_cycles = count_cycles_delta(G0, G1)\n",
    "\n",
    "    # 5) Spike detection quick stats\n",
    "    spikes_fan_in = 0\n",
    "    spikes_cyclo  = 0\n",
    "    for mod in common:\n",
    "        prev_metrics = x0.loc[mod] if mod in x0.index else pd.Series()\n",
    "        curr_metrics = x1.loc[mod] if mod in x1.index else pd.Series()\n",
    "        flags = metrics_spike_flags(prev_metrics, curr_metrics)\n",
    "        spikes_fan_in += int(flags[\"fan_in_spike\"])\n",
    "        spikes_cyclo  += int(flags[\"cyclomatic_spike\"])\n",
    "\n",
    "    drift_summary_rows.append({\n",
    "        \"version_from\": v0, \"version_to\": v1, \"tag_from\": t0, \"tag_to\": t1,\n",
    "        \"modules_added\": len(added_modules),\n",
    "        \"modules_removed\": len(removed_modules),\n",
    "        \"edges_added\": len(added_edges),\n",
    "        \"edges_removed\": len(removed_edges),\n",
    "        \"new_cycles\": new_cycles,\n",
    "        \"removed_cycles\": removed_cycles,\n",
    "        \"modules_with_fan_in_spike\": spikes_fan_in,\n",
    "        \"modules_with_cyclomatic_spike\": spikes_cyclo\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23604c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK ✅ Stage 4 complete\n",
      " - changes_modules.csv\n",
      " - changes_edges.csv\n",
      " - changes_metrics.csv\n",
      " - drift_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Write outputs\n",
    "changes_modules = pd.DataFrame(changes_modules_rows,\n",
    "    columns=[\"version_from\",\"version_to\",\"tag_from\",\"tag_to\",\"change_type\",\"module\"])\n",
    "changes_edges = pd.DataFrame(changes_edges_rows,\n",
    "    columns=[\"version_from\",\"version_to\",\"tag_from\",\"tag_to\",\"change_type\",\"src_module\",\"dst_module\"])\n",
    "changes_metrics = pd.DataFrame(changes_metrics_rows,\n",
    "    columns=[\"version_from\",\"version_to\",\"tag_from\",\"tag_to\",\"module\",\"fan_in_delta\",\"fan_out_delta\",\"cyclomatic_delta\",\"centrality_delta\"])\n",
    "drift_summary = pd.DataFrame(drift_summary_rows,\n",
    "    columns=[\"version_from\",\"version_to\",\"tag_from\",\"tag_to\",\"modules_added\",\"modules_removed\",\"edges_added\",\"edges_removed\",\"new_cycles\",\"removed_cycles\",\"modules_with_fan_in_spike\",\"modules_with_cyclomatic_spike\"])\n",
    "\n",
    "save_csv(changes_modules, \"changes_modules.csv\")\n",
    "save_csv(changes_edges, \"changes_edges.csv\")\n",
    "save_csv(changes_metrics, \"changes_metrics.csv\")\n",
    "save_csv(drift_summary, \"drift_summary.csv\")\n",
    "\n",
    "print(\"OK ✅ Stage 4 complete\")\n",
    "print(\" - changes_modules.csv\")\n",
    "print(\" - changes_edges.csv\")\n",
    "print(\" - changes_metrics.csv\")\n",
    "print(\" - drift_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc7f9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f150af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bd4cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b2c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32a683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
